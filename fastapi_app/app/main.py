import httpx
import base64
from fastapi import FastAPI, HTTPException, Header, Depends, UploadFile, File
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Optional, List
from . import config, database, models

app = FastAPI(
    title="Custom AI API Server with Qwen2.5-VL",
    description="A secure gateway to Ollama models with API key authentication + Qwen2.5-VL OCR endpoint."
)

# ì„œë²„ ì‹œì‘ ì‹œ DB ì´ˆê¸°í™”
@app.on_event("startup")
def on_startup():
    database.init_db()

# API í‚¤ ê²€ì¦ì„ ìœ„í•œ ì˜ì¡´ì„± ì£¼ì…
async def get_valid_api_key(x_api_key: str = Header(..., description="Your personal API Key.")):
    if not x_api_key:
        raise HTTPException(status_code=401, detail="API Key is missing")
    key_info = await database.validate_and_log_key(x_api_key)
    if not key_info:
        raise HTTPException(status_code=401, detail="Invalid or Inactive API Key")
    print(f"Request from '{key_info['owner']}' (Key: ...{x_api_key[-4:]})")
    return key_info

# [ê¸°ì¡´] ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ API
@app.get("/v1/models", tags=["Models"])
async def list_available_models(api_key: dict = Depends(get_valid_api_key)):
    """
    Ollama ì„œë²„ì— ë‹¤ìš´ë¡œë“œëœ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ëª¨ë¸ì˜ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    async with httpx.AsyncClient() as client:
        try:
            response = await client.get(f"{config.OLLAMA_BASE_URL}/api/tags")
            response.raise_for_status()
            return response.json()
        except httpx.RequestError as e:
            raise HTTPException(status_code=500, detail=f"Could not connect to Ollama: {e}")

# [ê¸°ì¡´] ë©”ì¸ ìƒì„± API
@app.post("/v1/generate", tags=["Generation"])
async def generate_completion(
    request: models.OllamaRequest,
    api_key: dict = Depends(get_valid_api_key)
):
    # Ollama ê³ ìœ  í¬ë§·ìœ¼ë¡œ ìš”ì²­ ë³¸ë¬¸ êµ¬ì„±
    ollama_payload = {
        "model": request.model,
        "prompt": request.prompt,
        "stream": request.stream
    }

    async with httpx.AsyncClient() as client:
        try:
            response = await client.post(
                f"{config.OLLAMA_BASE_URL}/api/generate",  # âœ… ì´ ê²½ë¡œê°€ Ollama native API
                json=ollama_payload,
                timeout=180.0
            )
            response.raise_for_status()
            response_data = response.json()

            # âœ… ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ DB ë¡œê·¸ ê¸°ë¡
            try:
                ai_response_text = response_data.get("response", "")
                await database.add_api_log(
                    owner=api_key.get("owner", "unknown"),
                    model=request.model,
                    prompt=request.prompt,
                    response=ai_response_text
                )
            except Exception as log_e:
                print(f"ë¡œê·¸ ê¸°ë¡ ì¤‘ ì—ëŸ¬ ë°œìƒ: {log_e}")

            return response_data
        except httpx.RequestError as e:
            raise HTTPException(status_code=500, detail=f"Error connecting to Ollama: {e}")


# ==================== ğŸ”¥ NEW: Qwen2.5-VL OCR ì „ìš© ì—”ë“œí¬ì¸íŠ¸ ====================

class QwenOCRRequest(BaseModel):
    """Qwen2.5-VL OCR ìš”ì²­ ëª¨ë¸"""
    image_base64: str
    prompt: Optional[str] = "ì´ ì´ë¯¸ì§€ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•íˆ ì½ì–´ì£¼ì„¸ìš”. í•œêµ­ì–´, ì˜ì–´, ìˆ«ìë¥¼ ëª¨ë‘ í¬í•¨í•´ì„œ ì¤„ë°”ê¿ˆë„ ìœ ì§€í•´ì£¼ì„¸ìš”."
    model: Optional[str] = "qwen2.5-vl:7b"
    temperature: Optional[float] = 0.1
    top_p: Optional[float] = 0.9

class QwenOCRResponse(BaseModel):
    """Qwen2.5-VL OCR ì‘ë‹µ ëª¨ë¸"""
    success: bool
    ocr_text: str
    model_used: str
    processing_time_ms: float
    error: Optional[str] = None

@app.post("/v1/qwen/ocr", tags=["Qwen2.5-VL"], response_model=QwenOCRResponse)
async def qwen_ocr_endpoint(
    request: QwenOCRRequest,
    api_key: dict = Depends(get_valid_api_key)
):
    """
    Qwen2.5-VLì„ ì‚¬ìš©í•œ ê³ ì„±ëŠ¥ OCR ì—”ë“œí¬ì¸íŠ¸
    
    - í•œêµ­ì–´ ìµœì í™”
    - Base64 ì´ë¯¸ì§€ ì…ë ¥
    - ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„
    - ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì§€ì›
    """
    import time
    start_time = time.time()
    
    try:
        # Qwen2.5-VL ì „ìš© í˜ì´ë¡œë“œ êµ¬ì„±
        qwen_payload = {
            "model": request.model,
            "prompt": request.prompt,
            "images": [request.image_base64],
            "stream": False,
            "options": {
                "temperature": request.temperature,
                "top_p": request.top_p
            }
        }
        
        async with httpx.AsyncClient(timeout=60.0) as client:
            try:
                response = await client.post(
                    f"{config.OLLAMA_BASE_URL}/api/generate",
                    json=qwen_payload,
                    headers={'Content-Type': 'application/json'}
                )
                response.raise_for_status()
                result = response.json()
                
                processing_time = (time.time() - start_time) * 1000
                ocr_text = result.get("response", "").strip()
                
                if not ocr_text:
                    ocr_text = "[No text detected]"
                
                # DB ë¡œê·¸ ê¸°ë¡ (ì„ íƒì‚¬í•­)
                try:
                    await database.add_api_log(
                        owner=api_key.get("owner", "unknown"),
                        model=request.model,
                        prompt=f"[OCR] {request.prompt[:100]}...",
                        response=ocr_text[:500]  # OCR ê²°ê³¼ëŠ” ê¸¸ ìˆ˜ ìˆìœ¼ë‹ˆ 500ìë§Œ
                    )
                except Exception as log_e:
                    print(f"OCR ë¡œê·¸ ê¸°ë¡ ì¤‘ ì—ëŸ¬: {log_e}")
                
                return QwenOCRResponse(
                    success=True,
                    ocr_text=ocr_text,
                    model_used=request.model,
                    processing_time_ms=round(processing_time, 2),
                    error=None
                )
                
            except httpx.TimeoutException:
                return QwenOCRResponse(
                    success=False,
                    ocr_text="",
                    model_used=request.model,
                    processing_time_ms=round((time.time() - start_time) * 1000, 2),
                    error="OCR processing timeout (60s exceeded)"
                )
            except httpx.RequestError as e:
                return QwenOCRResponse(
                    success=False,
                    ocr_text="",
                    model_used=request.model,
                    processing_time_ms=round((time.time() - start_time) * 1000, 2),
                    error=f"Network error: {str(e)}"
                )
                
    except Exception as e:
        return QwenOCRResponse(
            success=False,
            ocr_text="",
            model_used=request.model,
            processing_time_ms=round((time.time() - start_time) * 1000, 2),
            error=f"Server error: {str(e)}"
        )

@app.post("/v1/qwen/ocr-file", tags=["Qwen2.5-VL"], response_model=QwenOCRResponse)
async def qwen_ocr_file_upload(
    file: UploadFile = File(..., description="ì´ë¯¸ì§€ íŒŒì¼ (PNG, JPG, JPEG)"),
    prompt: str = "ì´ ì´ë¯¸ì§€ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•íˆ ì½ì–´ì£¼ì„¸ìš”. í•œêµ­ì–´, ì˜ì–´, ìˆ«ìë¥¼ ëª¨ë‘ í¬í•¨í•´ì„œ ì¤„ë°”ê¿ˆë„ ìœ ì§€í•´ì£¼ì„¸ìš”.",
    model: str = "qwen2.5-vl:7b",
    temperature: float = 0.1,
    top_p: float = 0.9,
    api_key: dict = Depends(get_valid_api_key)
):
    """
    íŒŒì¼ ì—…ë¡œë“œ ë°©ì‹ì˜ Qwen2.5-VL OCR ì—”ë“œí¬ì¸íŠ¸
    """
    import time
    start_time = time.time()
    
    # íŒŒì¼ íƒ€ì… ê²€ì¦
    if not file.content_type.startswith('image/'):
        raise HTTPException(status_code=400, detail="Only image files are supported")
    
    try:
        # íŒŒì¼ì„ base64ë¡œ ì¸ì½”ë”©
        file_content = await file.read()
        image_base64 = base64.b64encode(file_content).decode('utf-8')
        
        # ê¸°ì¡´ OCR ì—”ë“œí¬ì¸íŠ¸ ì¬ì‚¬ìš©
        request_obj = QwenOCRRequest(
            image_base64=image_base64,
            prompt=prompt,
            model=model,
            temperature=temperature,
            top_p=top_p
        )
        
        # ë‚´ë¶€ì ìœ¼ë¡œ qwen_ocr_endpoint í˜¸ì¶œ
        return await qwen_ocr_endpoint(request_obj, api_key)
        
    except Exception as e:
        return QwenOCRResponse(
            success=False,
            ocr_text="",
            model_used=model,
            processing_time_ms=round((time.time() - start_time) * 1000, 2),
            error=f"File processing error: {str(e)}"
        )

@app.get("/v1/qwen/health", tags=["Qwen2.5-VL"])
async def qwen_health_check(api_key: dict = Depends(get_valid_api_key)):
    """
    Qwen2.5-VL ëª¨ë¸ ìƒíƒœ í™•ì¸
    """
    async with httpx.AsyncClient() as client:
        try:
            # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
            response = await client.get(f"{config.OLLAMA_BASE_URL}/api/tags")
            models_data = response.json()
            
            qwen_models = [
                model for model in models_data.get("models", [])
                if "qwen2.5-vl" in model.get("name", "").lower()
            ]
            
            return {
                "status": "healthy" if qwen_models else "no_qwen_models",
                "available_qwen_models": [m["name"] for m in qwen_models],
                "recommended_model": "qwen2.5-vl:7b",
                "endpoints": [
                    "/v1/qwen/ocr",
                    "/v1/qwen/ocr-file",
                    "/v1/qwen/health"
                ]
            }
            
        except Exception as e:
            return {
                "status": "error",
                "error": str(e),
                "message": "Could not connect to Ollama server"
            }