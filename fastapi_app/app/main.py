import httpx
import base64
from fastapi import FastAPI, HTTPException, Header, Depends, UploadFile, File
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Optional, List
from . import config, database, models

app = FastAPI(
    title="Custom AI API Server with Qwen2.5-VL",
    description="A secure gateway to Ollama models with API key authentication + Qwen2.5-VL OCR endpoint."
)

# ì„œë²„ ì‹œì‘ ì‹œ DB ì´ˆê¸°í™”
@app.on_event("startup")
def on_startup():
    database.init_db()

# API í‚¤ ê²€ì¦ì„ ìœ„í•œ ì˜ì¡´ì„± ì£¼ì…
async def get_valid_api_key(x_api_key: str = Header(..., description="Your personal API Key.")):
    if not x_api_key:
        raise HTTPException(status_code=401, detail="API Key is missing")
    key_info = await database.validate_and_log_key(x_api_key)
    if not key_info:
        raise HTTPException(status_code=401, detail="Invalid or Inactive API Key")
    print(f"Request from '{key_info['owner']}' (Key: ...{x_api_key[-4:]})")
    return key_info

# [ê¸°ì¡´] ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ API
@app.get("/v1/models", tags=["Models"])
async def list_available_models(api_key: dict = Depends(get_valid_api_key)):
    """
    Ollama ì„œë²„ì— ë‹¤ìš´ë¡œë“œëœ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ëª¨ë¸ì˜ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    all_models = []
    all_model_names = set()

    async with httpx.AsyncClient() as client:
        for endpoint in set(config.OLLAMA_ENDPOINTS.values()):
            try:
                response = await client.get(f"{endpoint}/api/tags")
                response.raise_for_status()
                models_data = response.json()
                
                if "models" in models_data:
                    for model in models_data["models"]:
                        if model["name"] not in all_model_names:
                            all_models.append(model)
                            all_model_names.add(model["name"])

            except httpx.RequestError as e:
                # ê°œë³„ ì—”ë“œí¬ì¸íŠ¸ ì‹¤íŒ¨ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
                print(f"Warning: Could not connect to Ollama at {endpoint}. Error: {e}")
                continue

    if not all_models:
        raise HTTPException(status_code=500, detail="Could not retrieve models from any Ollama server.")

    return {"models": all_models}

# [ê¸°ì¡´] ë©”ì¸ ìƒì„± API
@app.post("/v1/generate", tags=["Generation"])
async def generate_completion(
    request: models.OllamaRequest,
    api_key: dict = Depends(get_valid_api_key)
):
    model_name = request.model.strip().lower()

    if model_name not in config.SUPPORTED_MODELS:
        raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ì…ë‹ˆë‹¤: {model_name}")

    endpoint = config.OLLAMA_ENDPOINTS.get(model_name)
    if not endpoint:
        raise HTTPException(status_code=500, detail=f"ëª¨ë¸ '{model_name}'ì— ëŒ€í•œ Ollama ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    ollama_payload = {
        "model": model_name,
        "prompt": request.prompt,
        "stream": request.stream,
        "options": request.options or {}
    }

    async with httpx.AsyncClient() as client:
        try:
            response = await client.post(
                f"{endpoint}/api/generate",
                json=ollama_payload,
                timeout=180.0
            )
            response.raise_for_status()
            response_data = response.json()

            # ë¡œê·¸ ì €ì¥
            try:
                ai_response_text = response_data.get("response", "")
                await database.add_api_log(
                    owner=api_key.get("owner", "unknown"),
                    model=model_name,
                    prompt=request.prompt,
                    response=ai_response_text
                )
            except Exception as log_e:
                print(f"ë¡œê·¸ ê¸°ë¡ ì¤‘ ì—ëŸ¬ ë°œìƒ: {log_e}")

            return response_data

        except httpx.RequestError as e:
            raise HTTPException(status_code=500, detail=f"Ollama ì—°ê²° ì˜¤ë¥˜: {e}")

# ==================== ğŸ”¥ NEW: Qwen2.5-VL OCR ì „ìš© ì—”ë“œí¬ì¸íŠ¸ ====================

class QwenOCRRequest(BaseModel):
    """Qwen2.5-VL OCR ìš”ì²­ ëª¨ë¸"""
    image_base64: str
    prompt: Optional[str] = "ì´ ì´ë¯¸ì§€ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•íˆ ì½ì–´ì£¼ì„¸ìš”. í•œêµ­ì–´, ì˜ì–´, ìˆ«ìë¥¼ ëª¨ë‘ í¬í•¨í•´ì„œ ì¤„ë°”ê¿ˆë„ ìœ ì§€í•´ì£¼ì„¸ìš”."
    model: Optional[str] = "qwen2.5vl:7b"
    temperature: Optional[float] = 0.1
    top_p: Optional[float] = 0.9

class QwenOCRResponse(BaseModel):
    """Qwen2.5-VL OCR ì‘ë‹µ ëª¨ë¸"""
    success: bool
    ocr_text: str
    model_used: str
    processing_time_ms: float
    error: Optional[str] = None

@app.post("/v1/qwen/ocr", tags=["Qwen2.5-VL"], response_model=QwenOCRResponse)
async def qwen_ocr_endpoint(
    request: QwenOCRRequest,
    api_key: dict = Depends(get_valid_api_key)
):
    """
    Qwen2.5-VLì„ ì‚¬ìš©í•œ ê³ ì„±ëŠ¥ OCR ì—”ë“œí¬ì¸íŠ¸
    
    - í•œêµ­ì–´ ìµœì í™”
    - Base64 ì´ë¯¸ì§€ ì…ë ¥
    - ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„
    - ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì§€ì›
    """
    import time
    start_time = time.time()
    
    try:
        # Qwen2.5-VL ì „ìš© í˜ì´ë¡œë“œ êµ¬ì„±
        qwen_payload = {
            "model": request.model,
            "prompt": request.prompt,
            "images": [request.image_base64],
            "stream": False,
            "options": {
                "temperature": request.temperature,
                "top_p": request.top_p
            }
        }
        
        endpoint = config.OLLAMA_ENDPOINTS.get(request.model)
        if not endpoint:
            raise HTTPException(status_code=500, detail=f"ëª¨ë¸ '{request.model}'ì— ëŒ€í•œ Ollama ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        async with httpx.AsyncClient(timeout=120.0) as client:
            try:
                response = await client.post(
                    f"{endpoint}/api/generate",
                    json=qwen_payload,
                    headers={'Content-Type': 'application/json'}
                )
                response.raise_for_status()
                result = response.json()
                
                processing_time = (time.time() - start_time) * 1000
                ocr_text = result.get("response", "").strip()
                
                if not ocr_text:
                    ocr_text = "[No text detected]"
                
                # DB ë¡œê·¸ ê¸°ë¡ (ì„ íƒì‚¬í•­)
                try:
                    await database.add_api_log(
                        owner=api_key.get("owner", "unknown"),
                        model=request.model,
                        prompt=f"[OCR] {request.prompt[:100]}...",
                        response=ocr_text[:500]  # OCR ê²°ê³¼ëŠ” ê¸¸ ìˆ˜ ìˆìœ¼ë‹ˆ 500ìë§Œ
                    )
                except Exception as log_e:
                    print(f"OCR ë¡œê·¸ ê¸°ë¡ ì¤‘ ì—ëŸ¬: {log_e}")
                
                return QwenOCRResponse(
                    success=True,
                    ocr_text=ocr_text,
                    model_used=request.model,
                    processing_time_ms=round(processing_time, 2),
                    error=None
                )
                
            except httpx.TimeoutException:
                return QwenOCRResponse(
                    success=False,
                    ocr_text="",
                    model_used=request.model,
                    processing_time_ms=round((time.time() - start_time) * 1000, 2),
                    error="OCR processing timeout (120s exceeded)"
                )
            except httpx.RequestError as e:
                return QwenOCRResponse(
                    success=False,
                    ocr_text="",
                    model_used=request.model,
                    processing_time_ms=round((time.time() - start_time) * 1000, 2),
                    error=f"Network error: {str(e)}"
                )
                
    except Exception as e:
        return QwenOCRResponse(
            success=False,
            ocr_text="",
            model_used=request.model,
            processing_time_ms=round((time.time() - start_time) * 1000, 2),
            error=f"Server error: {str(e)}"
        )

@app.post("/v1/qwen/ocr-file", tags=["Qwen2.5-VL"], response_model=QwenOCRResponse)
async def qwen_ocr_file_upload(
    file: UploadFile = File(..., description="ì´ë¯¸ì§€ íŒŒì¼ (PNG, JPG, JPEG)"),
    prompt: str = "ì´ ì´ë¯¸ì§€ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•íˆ ì½ì–´ì£¼ì„¸ìš”. í•œêµ­ì–´, ì˜ì–´, ìˆ«ìë¥¼ ëª¨ë‘ í¬í•¨í•´ì„œ ì¤„ë°”ê¿ˆë„ ìœ ì§€í•´ì£¼ì„¸ìš”.",
    model: str = "qwen2.5vl:7b",
    temperature: float = 0.1,
    top_p: float = 0.9,
    api_key: dict = Depends(get_valid_api_key)
):
    """
    íŒŒì¼ ì—…ë¡œë“œ ë°©ì‹ì˜ Qwen2.5-VL OCR ì—”ë“œí¬ì¸íŠ¸
    """
    import time
    start_time = time.time()
    
    # íŒŒì¼ íƒ€ì… ê²€ì¦
    if not file.content_type.startswith('image/'):
        raise HTTPException(status_code=400, detail="Only image files are supported")
    
    try:
        # íŒŒì¼ì„ base64ë¡œ ì¸ì½”ë”©
        file_content = await file.read()
        image_base64 = base64.b64encode(file_content).decode('utf-8')
        
        # ê¸°ì¡´ OCR ì—”ë“œí¬ì¸íŠ¸ ì¬ì‚¬ìš©
        request_obj = QwenOCRRequest(
            image_base64=image_base64,
            prompt=prompt,
            model=model,
            temperature=temperature,
            top_p=top_p
        )
        
        # ë‚´ë¶€ì ìœ¼ë¡œ qwen_ocr_endpoint í˜¸ì¶œ
        return await qwen_ocr_endpoint(request_obj, api_key)
        
    except Exception as e:
        return QwenOCRResponse(
            success=False,
            ocr_text="",
            model_used=model,
            processing_time_ms=round((time.time() - start_time) * 1000, 2),
            error=f"File processing error: {str(e)}"
        )

@app.get("/v1/qwen/health", tags=["Qwen2.5-VL"])
async def qwen_health_check(api_key: dict = Depends(get_valid_api_key)):
    """
    Qwen2.5-VL ëª¨ë¸ ìƒíƒœ í™•ì¸
    """
    qwen_models = []
    errors = []

    async with httpx.AsyncClient() as client:
        for endpoint in set(config.OLLAMA_ENDPOINTS.values()):
            try:
                response = await client.get(f"{endpoint}/api/tags")
                response.raise_for_status()
                models_data = response.json()
                
                for model in models_data.get("models", []):
                    if "qwen" in model.get("name", "").lower():
                        qwen_models.append(model["name"])

            except Exception as e:
                errors.append(f"Could not connect to {endpoint}: {str(e)}")
                continue

    if not qwen_models and errors:
        return {
            "status": "error",
            "errors": errors,
            "message": "Could not connect to any Ollama server or no Qwen models found."
        }

    return {
        "status": "healthy" if qwen_models else "no_qwen_models_found",
        "available_qwen_models": list(set(qwen_models)),
        "recommended_model": "qwen2.5vl:7b",
        "endpoints": [
            "/v1/qwen/ocr",
            "/v1/qwen/ocr-file",
            "/v1/qwen/health"
        ]
    }

# ==================== ğŸš€ NEW: PaddleOCR ì—”ë“œí¬ì¸íŠ¸ ====================
from paddleocr import PaddleOCR
import numpy as np
from PIL import Image
import io
import time

# PaddleOCR ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™” (GPU ì‚¬ìš©, í•œêµ­ì–´+ì˜ì–´ ëª¨ë¸)
# ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ë¡œë“œë˜ë„ë¡ ì „ì—­ìœ¼ë¡œ ì„ ì–¸
try:
    print("Initializing PaddleOCR...")
    paddle_ocr_instance = PaddleOCR(use_angle_cls=True, lang='korean', use_gpu=True)
    print("PaddleOCR initialized successfully.")
except Exception as e:
    print(f"Error initializing PaddleOCR: {e}")
    paddle_ocr_instance = None

class PaddleOCRResponse(BaseModel):
    success: bool
    results: Optional[List[dict]] = None
    processing_time_ms: float
    error: Optional[str] = None

@app.post("/v1/paddle/ocr", tags=["PaddleOCR"], response_model=PaddleOCRResponse)
async def paddle_ocr_endpoint(
    file: UploadFile = File(..., description="ì´ë¯¸ì§€ íŒŒì¼ (PNG, JPG, JPEG)"),
    api_key: dict = Depends(get_valid_api_key)
):
    """
    PaddleOCRì„ ì‚¬ìš©í•œ ê³ ì„±ëŠ¥ OCR ì—”ë“œí¬ì¸íŠ¸

    - GPU ê°€ì† ì§€ì› (ì„œë²„ í™˜ê²½ì— ë”°ë¼ ì„¤ì •)
    - í•œêµ­ì–´, ì˜ì–´, ìˆ«ì ë“± ë‹¤êµ­ì–´ ì¸ì‹
    - ì´ë¯¸ì§€ íŒŒì¼ì„ ì§ì ‘ ì—…ë¡œë“œí•˜ì—¬ OCR ìˆ˜í–‰
    """
    if not paddle_ocr_instance:
        raise HTTPException(status_code=500, detail="PaddleOCR is not initialized. Check server logs for errors.")

    start_time = time.time()

    # íŒŒì¼ íƒ€ì… ê²€ì¦
    if not file.content_type.startswith('image/'):
        raise HTTPException(status_code=400, detail="Only image files are supported")

    try:
        # ì´ë¯¸ì§€ íŒŒì¼ ì½ê¸°
        contents = await file.read()
        
        # Pillowë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì—´ê¸°
        img = Image.open(io.BytesIO(contents))
        
        # ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
        img_np = np.array(img)

        # PaddleOCR ì‹¤í–‰
        result = paddle_ocr_instance.ocr(img_np, cls=True)
        
        processing_time = (time.time() - start_time) * 1000

        # ê²°ê³¼ í¬ë§·íŒ…
        formatted_results = []
        if result and result[0]:
            for line in result[0]:
                box = line[0]
                text, confidence = line[1]
                formatted_results.append({
                    "text": text,
                    "confidence": round(confidence, 4),
                    "box": {
                        "top_left": [int(p) for p in box[0]],
                        "top_right": [int(p) for p in box[1]],
                        "bottom_right": [int(p) for p in box[2]],
                        "bottom_left": [int(p) for p in box[3]],
                    }
                })

        return PaddleOCRResponse(
            success=True,
            results=formatted_results,
            processing_time_ms=round(processing_time, 2)
        )

    except Exception as e:
        processing_time = (time.time() - start_time) * 1000
        return PaddleOCRResponse(
            success=False,
            processing_time_ms=round(processing_time, 2),
            error=f"An error occurred during OCR processing: {str(e)}"
        )