version: "3.9"

services:
  # GPU 0 - Qwen2.5-VL:7b ì „ìš© (ê³ ì •)
  ollama_gpu0:
    image: ollama/ollama
    container_name: ollama_gpu0
    ports:
      - "11436:11434"
    volumes:
      - ollama_gpu0_data:/root/.ollama
    restart: always
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=0
      - OLLAMA_KEEP_ALIVE=-1              # ğŸ”¥ ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ì˜êµ¬ ìœ ì§€
      - OLLAMA_MAX_LOADED_MODELS=1        # ë™ì‹œ ë¡œë“œ ëª¨ë¸ ìˆ˜ ì œí•œ
      - OLLAMA_NUM_PARALLEL=4             # ë³‘ë ¬ ìš”ì²­ ì²˜ë¦¬
      - OLLAMA_MAX_QUEUE=10               # ëŒ€ê¸° í í¬ê¸°

  # GPU 1 - gpt-oss:20b ì „ìš© (ê³ ì •)
  ollama_gpu1:
    image: ollama/ollama
    container_name: ollama_gpu1
    ports:
      - "11435:11434"
    volumes:
      - ollama_gpu1_data:/root/.ollama
    restart: always
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=1
      - OLLAMA_KEEP_ALIVE=-1              # ğŸ”¥ ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ì˜êµ¬ ìœ ì§€
      - OLLAMA_MAX_LOADED_MODELS=1
      - OLLAMA_NUM_PARALLEL=4
      - OLLAMA_MAX_QUEUE=10

  # FastAPI Gateway
  fastapi_app:
    build: ./fastapi_app
    container_name: fastapi_gateway
    ports:
      - "8010:8000"
    volumes:
      - api_db_data:/app/database
    restart: always
    depends_on:
      - ollama_gpu0
      - ollama_gpu1
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=0

  # NGINX Reverse Proxy
  nginx:
    image: nginx:latest
    container_name: nginx_proxy
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/conf.d/default.conf
    restart: always
    depends_on:
      - fastapi_app

volumes:
  ollama_gpu0_data:
  ollama_gpu1_data:
  api_db_data:
