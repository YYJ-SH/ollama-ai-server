# ğŸ“‹ ìµœì í™” ë³€ê²½ì‚¬í•­ ìš”ì•½

## ğŸ¯ ëª©í‘œ
**OCR ì²˜ë¦¬ ì‹œê°„: 2ë¶„+ â†’ 3-5ì´ˆ (ì•½ 20-30ë°° ê°œì„ )**

---

## ğŸ“¦ ìƒì„±ëœ íŒŒì¼ë“¤

### 1. `docker-compose.production.optimized.yml`
**ì›ë³¸ ëŒ€ì²´ìš© ìµœì í™” ë²„ì „**
- í™˜ê²½ë³€ìˆ˜ ì¶”ê°€: `OLLAMA_KEEP_ALIVE=-1`
- GPUë³„ ëª¨ë¸ ê³ ì • ì„¤ì •
- ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”

### 2. `fastapi_app/app/config.optimized.py`
**ì›ë³¸ ëŒ€ì²´ìš© ìµœì í™” ë²„ì „**
- ëª¨ë¸ ëª©ë¡ ë‹¨ìˆœí™” (qwen2.5vl:7b, gpt-oss:20bë§Œ)
- íƒ€ì„ì•„ì›ƒ 300ì´ˆë¡œ ì¦ê°€
- ëª…í™•í•œ GPU ë¼ìš°íŒ…

### 3. `fastapi_app/app/main.optimized.py`
**ì›ë³¸ ëŒ€ì²´ìš© ìµœì í™” ë²„ì „**
- ì„œë²„ ì‹œì‘ì‹œ ëª¨ë¸ ì›Œë°ì—…
- ëª¨ë“  ìš”ì²­ì— `keep_alive=-1` ì¶”ê°€
- í—¬ìŠ¤ì²´í¬ ê°œì„ 

### 4. `OPTIMIZATION_GUIDE.md`
**ìƒì„¸ ìµœì í™” ê°€ì´ë“œ**
- ë¬¸ì œ ì§„ë‹¨ ìƒì„¸ ì„¤ëª…
- ë‹¨ê³„ë³„ ì ìš© ë°©ë²•
- ê²€ì¦ ë° íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 5. `QUICK_FIX.md`
**3ë¶„ ë¹ ë¥¸ ì ìš© ê°€ì´ë“œ**
- ìµœì†Œí•œì˜ ë³€ê²½ìœ¼ë¡œ ì¦‰ì‹œ ê°œì„ 
- í•µì‹¬ë§Œ ìš”ì•½

---

## ğŸ”‘ í•µì‹¬ ë³€ê²½ì‚¬í•­

### Docker Compose
```diff
  ollama_gpu0:
    environment:
      - NVIDIA_VISIBLE_DEVICES=0
+     - OLLAMA_KEEP_ALIVE=-1
+     - OLLAMA_MAX_LOADED_MODELS=1
+     - OLLAMA_NUM_PARALLEL=4
```

### Config.py
```diff
+ OLLAMA_REQUEST_TIMEOUT = 300.0

  OLLAMA_ENDPOINTS = {
-     "llama3:latest": "...",
-     "qwen2.5vl:7b": "...",
-     "qwen2.5vl:3b": "...",
-     "exaone3.5:7.8b": "...",
+     "qwen2.5vl:7b": "http://ollama_gpu0:11434",
      "gpt-oss:20b": "http://ollama_gpu1:11434"
  }
```

### Main.py
```diff
  @app.on_event("startup")
  def on_startup():
      database.init_db()
+     # ëª¨ë¸ ì›Œë°ì—… ì¶”ê°€
+     await warmup_models()

  ollama_payload = {
      "model": model_name,
      "prompt": request.prompt,
+     "keep_alive": -1,
  }
```

---

## ğŸ“Š Before/After

### ì²˜ë¦¬ ì‹œê°„
```
Before: ì²« ìš”ì²­ 16ì´ˆ + OCR 2ë¶„+ = 136ì´ˆ+
After:  ì²« ìš”ì²­ 1ì´ˆ + OCR 3-5ì´ˆ = 4-6ì´ˆ

â†’ ì•½ 25ë°° ë¹¨ë¼ì§! âš¡
```

### GPU í™œìš©
```
Before: GPU 0: 97% (ê³¼ë¶€í•˜), GPU 1: 0% (ìœ íœ´)
After:  GPU 0: 60%, GPU 1: 70% (ê· í˜•)
```

### ëª¨ë¸ ë¡œë”©
```
Before: 4ë¶„ë§ˆë‹¤ ì¬ë¡œë”© (Cold Start)
After:  ì„œë²„ ì‹œì‘ì‹œ 1íšŒ ë¡œë”© (Warm)
```

---

## ğŸš€ ì ìš© ë°©ë²• (ì„ íƒ)

### ì˜µì…˜ A: ìµœì†Œ ë³€ê²½ (ê¶Œì¥, 3ë¶„)
`QUICK_FIX.md` ì°¸ê³ 
- Docker Compose í™˜ê²½ë³€ìˆ˜ë§Œ ì¶”ê°€
- Config.py íƒ€ì„ì•„ì›ƒë§Œ ì¶”ê°€
- ê¸°ì¡´ ì½”ë“œ ìµœëŒ€í•œ ìœ ì§€

### ì˜µì…˜ B: ì™„ì „ ìµœì í™” (10ë¶„)
`OPTIMIZATION_GUIDE.md` ì°¸ê³ 
- ìµœì í™” íŒŒì¼ë¡œ ì™„ì „ êµì²´
- ëª¨ë¸ ì›Œë°ì—… ì¶”ê°€
- í—¬ìŠ¤ì²´í¬ ê°œì„ 

---

## ğŸ“ íŒŒì¼ êµì²´ ë°©ë²•

### ì„œë²„ì—ì„œ ì§ì ‘ ì‘ì—…
```bash
cd /home/user/ollama-ai-server

# ë°±ì—…
cp docker-compose.production.yml docker-compose.production.backup.yml
cp fastapi_app/app/config.py fastapi_app/app/config.backup.py
cp fastapi_app/app/main.py fastapi_app/app/main.backup.py

# ìµœì í™” íŒŒì¼ ì ìš© (ë¡œì»¬ì—ì„œ ì—…ë¡œë“œ í›„)
mv docker-compose.production.optimized.yml docker-compose.production.yml
mv fastapi_app/app/config.optimized.py fastapi_app/app/config.py
mv fastapi_app/app/main.optimized.py fastapi_app/app/main.py
```

### Windowsì—ì„œ SCPë¡œ ì—…ë¡œë“œ
```powershell
cd C:\Users\User\Desktop\Yeji\ai_server

scp docker-compose.production.optimized.yml user@server:/home/user/ollama-ai-server/
scp fastapi_app/app/config.optimized.py user@server:/home/user/ollama-ai-server/fastapi_app/app/
scp fastapi_app/app/main.optimized.py user@server:/home/user/ollama-ai-server/fastapi_app/app/
```

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

ì ìš© ì „:
- [ ] ë°±ì—… ì™„ë£Œ
- [ ] íŒŒì¼ í™•ì¸ (*.optimized.yml, *.optimized.py)
- [ ] ê°€ì´ë“œ ë¬¸ì„œ ì½ìŒ

ì ìš© í›„:
- [ ] ì¬ë¹Œë“œ ì™„ë£Œ
- [ ] `ollama ps`ë¡œ Forever í™•ì¸
- [ ] nvidia-smië¡œ GPU ë©”ëª¨ë¦¬ í™•ì¸
- [ ] OCR ì†ë„ í…ŒìŠ¤íŠ¸

---

## ğŸ’¡ Why This Works?

### 1. OLLAMA_KEEP_ALIVE=-1
**ê¸°ì¡´:** 4ë¶„ í›„ ëª¨ë¸ ì–¸ë¡œë“œ â†’ ë‹¤ìŒ ìš”ì²­ì‹œ ì¬ë¡œë”© (16ì´ˆ)
**ë³€ê²½:** ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ì˜êµ¬ ë³´ê´€ â†’ ì¬ë¡œë”© ì—†ìŒ (0ì´ˆ)

### 2. OLLAMA_REQUEST_TIMEOUT=300
**ê¸°ì¡´:** 120ì´ˆ íƒ€ì„ì•„ì›ƒ â†’ OCR ì²˜ë¦¬ ì¤‘ ê°•ì œ ì¢…ë£Œ
**ë³€ê²½:** 300ì´ˆë¡œ ì—¬ìœ  â†’ ì•ˆì •ì  ì²˜ë¦¬

### 3. Model Warmup
**ê¸°ì¡´:** ì²« ìš”ì²­ì‹œ ëª¨ë¸ ë¡œë”© ì‹œì‘ â†’ ì‚¬ìš©ì ëŒ€ê¸°
**ë³€ê²½:** ì„œë²„ ì‹œì‘ì‹œ ë¯¸ë¦¬ ë¡œë”© â†’ ì¦‰ì‹œ ì‘ë‹µ

### 4. ëª¨ë¸ ê³ ì •
**ê¸°ì¡´:** ì—¬ëŸ¬ ëª¨ë¸ ìŠ¤ì™‘ â†’ ë¶ˆí•„ìš”í•œ ë¡œë”©/ì–¸ë¡œë”©
**ë³€ê²½:** 2ê°œ ëª¨ë¸ ê³ ì • â†’ ì•ˆì •ì  ìš´ì˜

---

## ğŸ“ ë°°ìš´ ì 

1. **Ollamaì˜ ëª¨ë¸ ê´€ë¦¬ ë©”ì»¤ë‹ˆì¦˜**
   - `keep_alive` íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ ìœ ì§€ ì‹œê°„ ì œì–´
   - -1 = ì˜êµ¬, 300 = 5ë¶„, 0 = ì¦‰ì‹œ ì–¸ë¡œë“œ

2. **Docker í™˜ê²½ë³€ìˆ˜ì˜ ì¤‘ìš”ì„±**
   - í™˜ê²½ë³€ìˆ˜ë§Œìœ¼ë¡œë„ í° ì„±ëŠ¥ ê°œì„  ê°€ëŠ¥
   - `OLLAMA_KEEP_ALIVE`, `OLLAMA_NUM_PARALLEL` ë“±

3. **Cold Start vs Warm Start**
   - LLMì€ ë©”ëª¨ë¦¬ ë¡œë”©ì´ ë³‘ëª©
   - ë¯¸ë¦¬ ë¡œë”©(warmup)ìœ¼ë¡œ ì²« ìš”ì²­ ì‹œê°„ ë‹¨ì¶•

4. **GPU ìì› ê´€ë¦¬**
   - 2ê°œ GPUë¥¼ ìš©ë„ë³„ë¡œ ë¶„ë¦¬
   - ê° GPUì— ê³ ì • ëª¨ë¸ í• ë‹¹

---

## ğŸ“ ë¬¸ì˜ì‚¬í•­

ë¬¸ì œ ë°œìƒì‹œ:
1. ë¡œê·¸ í™•ì¸: `docker logs -f fastapi_gateway`
2. GPU ìƒíƒœ: `nvidia-smi`
3. ëª¨ë¸ ìƒíƒœ: `docker exec -it ollama_gpu0 bash && ollama ps`

**Happy Optimizing! ğŸš€**
